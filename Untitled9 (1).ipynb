{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1c89908-a228-4c1a-aa97-b73ff7aaf933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files to 'spambase_data' folder.\n",
      "Data loaded. Shape: (4601, 58)\n",
      "\n",
      "First 5 rows of the data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define paths and column names\n",
    "zip_path = 'spambase.zip'  # Your uploaded zip filename\n",
    "extract_folder = 'spambase_data'\n",
    "data_path = f'{extract_folder}/spambase.data' \n",
    "\n",
    "column_names = [\n",
    "    'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our',\n",
    "    'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n",
    "    'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses',\n",
    "    'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "    'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp',\n",
    "    'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs',\n",
    "    'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n",
    "    'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "    'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re',\n",
    "    'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
    "    'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$', 'char_freq_#',\n",
    "    'capital_run_length_average', 'capital_run_length_longest', 'capital_run_length_total',\n",
    "    'spam' # Target column\n",
    "]\n",
    "\n",
    "# 1. Extract the data\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_folder)\n",
    "print(f\"Extracted files to '{extract_folder}' folder.\")\n",
    "\n",
    "# 2. Load the data\n",
    "data = pd.read_csv(data_path, header=None, names=column_names)\n",
    "print(\"Data loaded. Shape:\", data.shape)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst 5 rows of the data:\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fc18140-981a-48f5-8357-e12d40a1f170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (X_train, y_train): (3220, 57), (3220,)\n",
      "Testing set shape (X_test, y_test): (1381, 57), (1381,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = data.drop('spam', axis=1).values\n",
    "y = data['spam'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set shape (X_train, y_train): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set shape (X_test, y_test): {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8d008d-d340-42e6-8f5b-799ba3c25040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Class Priors:\n",
      "  Class 0 (Spam=0): 0.6161\n",
      "  Class 1 (Spam=1): 0.3839\n",
      "\n",
      "First 5 Means for Class 0 (Not Spam): [0.07296875 0.21552923 0.20525706 0.000625   0.17731351]\n",
      "First 5 Standard Deviations for Class 1 (Spam): [0.31196498 0.37666884 0.48547619 2.15584132 0.72044424]\n"
     ]
    }
   ],
   "source": [
    "# Find the unique classes (0: not spam, 1: spam)\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# Calculate class priors P(C=c)\n",
    "# priors[c] = (Count of class c) / (Total count)\n",
    "priors = {c: np.mean(y_train == c) for c in classes}\n",
    "\n",
    "# Calculate mean (Œº) and standard deviation (œÉ) for each feature per class\n",
    "# Note: ddof=1 for sample standard deviation\n",
    "means = {c: np.mean(X_train[y_train == c], axis=0) for c in classes}\n",
    "stds = {c: np.std(X_train[y_train == c], axis=0, ddof=1) for c in classes}\n",
    "\n",
    "print(\"Calculated Class Priors:\")\n",
    "for c, prior in priors.items():\n",
    "    print(f\"  Class {c} (Spam={c}): {prior:.4f}\")\n",
    "\n",
    "print(\"\\nFirst 5 Means for Class 0 (Not Spam):\", means[0][:5])\n",
    "print(\"First 5 Standard Deviations for Class 1 (Spam):\", stds[1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d38e5a03-9968-4699-b585-448ccb5494fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction functions defined.\n"
     ]
    }
   ],
   "source": [
    "def likelihood(x, mean, std):\n",
    "    \"\"\"\n",
    "    Calculates the sum of log-probabilities (log-likelihood) for a single sample x,\n",
    "    assuming a Gaussian distribution for each feature.\n",
    "    P(X=x | C=c) = Product over features P(X_i=x_i | C=c)\n",
    "    log P(X=x | C=c) = Sum over features log P(X_i=x_i | C=c)\n",
    "    \"\"\"\n",
    "    # Use a small constant to prevent division by zero for features with std=0\n",
    "    std_safe = np.where(std == 0, 1e-6, std) \n",
    "    \n",
    "    # norm.logpdf calculates log P(X_i=x_i | C=c)\n",
    "    # np.sum adds them up due to Naive Bayes assumption of independence\n",
    "    return np.sum(norm.logpdf(x, mean, std_safe))\n",
    "\n",
    "def predict(X):\n",
    "    \"\"\"\n",
    "    Predicts the class for an array of samples X using the maximum a posteriori principle.\n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "    for x in X:\n",
    "        posteriors = {}\n",
    "        for c in classes:\n",
    "            # 1. Log Prior: log P(C=c)\n",
    "            log_prior = np.log(priors[c])\n",
    "            \n",
    "            # 2. Log Likelihood: log P(X=x | C=c)\n",
    "            log_likelihood = likelihood(x, means[c], stds[c])\n",
    "            \n",
    "            # 3. Log Posterior (Proportional): log P(X=x|C=c) + log P(C=c)\n",
    "            posteriors[c] = log_prior + log_likelihood\n",
    "        \n",
    "        # Select the class with the highest log-posterior value (Maximum A Posteriori)\n",
    "        y_pred.append(max(posteriors, key=posteriors.get))\n",
    "        \n",
    "    return np.array(y_pred)\n",
    "\n",
    "print(\"Prediction functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3060ba-919b-4d07-b56a-b0a48412134a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gaussian Naive Bayes Model Evaluation ---\n",
      "Accuracy: 0.8161\n",
      "\n",
      "Confusion Matrix:\n",
      "[[583 221]\n",
      " [ 33 544]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.73      0.82       804\n",
      "           1       0.71      0.94      0.81       577\n",
      "\n",
      "    accuracy                           0.82      1381\n",
      "   macro avg       0.83      0.83      0.82      1381\n",
      "weighted avg       0.85      0.82      0.82      1381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"--- Gaussian Naive Bayes Model Evaluation ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83a9fca1-f420-41c1-9b95-8428b2aa19b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated Class Priors:\n",
      "  P(Class 0): 0.6161\n",
      "  P(Class 1): 0.3839\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_train is your training target array (e.g., [0, 1, 0, 1, 1, ...])\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "# --- PRIOR PROBABILITY CODE ---\n",
    "# Calculate class priors P(C=c)\n",
    "# np.mean(y_train == c) computes (count of c) / (total samples)\n",
    "priors = {c: np.mean(y_train == c) for c in classes}\n",
    "# -----------------------------\n",
    "\n",
    "print(\"Calculated Class Priors:\")\n",
    "for c, prior in priors.items():\n",
    "    print(f\"  P(Class {c}): {prior:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59735262-0f84-43b9-8603-df2542819edb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m log_prior \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(priors[c])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2. Log Likelihood: log P(X=x | C=c)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m likelihood(x, means[c], stds[c])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 3. Log Posterior (Proportional): Sum of Log Prior and Log Likelihood\u001b[39;00m\n\u001b[0;32m     19\u001b[0m posteriors[c] \u001b[38;5;241m=\u001b[39m log_prior \u001b[38;5;241m+\u001b[39m log_likelihood\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have a single test sample 'x' and previously calculated 'priors', 'means', and 'stds'\n",
    "\n",
    "# Define the Log Likelihood function first\n",
    "def likelihood(x, mean, std):\n",
    "    # Sum of log-probabilities from Gaussian PDF (Log Likelihood: log P(X=x | C=c))\n",
    "    std_safe = np.where(std == 0, 1e-6, std) \n",
    "    return np.sum(norm.logpdf(x, mean, std_safe))\n",
    "\n",
    "# --- LOG POSTERIOR PROBABILITY CODE (Proportional) ---\n",
    "posteriors = {}\n",
    "for c in classes:\n",
    "    # 1. Log Prior: log P(C=c)\n",
    "    log_prior = np.log(priors[c])\n",
    "\n",
    "    # 2. Log Likelihood: log P(X=x | C=c)\n",
    "    log_likelihood = likelihood(x, means[c], stds[c])\n",
    "\n",
    "    # 3. Log Posterior (Proportional): Sum of Log Prior and Log Likelihood\n",
    "    posteriors[c] = log_prior + log_likelihood\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(f\"Log Posterior (Proportional) for Class 0: {posteriors[0]:.4f}\")\n",
    "print(f\"Log Posterior (Proportional) for Class 1: {posteriors[1]:.4f}\")\n",
    "\n",
    "# The prediction is the class with the higher value\n",
    "prediction = max(posteriors, key=posteriors.get)\n",
    "print(f\"Prediction: Class {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c20241db-1243-4f29-818e-94a663fcbb72",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m log_prior \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(priors[c])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2. Log Likelihood: log P(X=x | C=c)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m likelihood(x, means[c], stds[c])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 3. Log Posterior (Proportional): Sum of Log Prior and Log Likelihood\u001b[39;00m\n\u001b[0;32m     19\u001b[0m posteriors[c] \u001b[38;5;241m=\u001b[39m log_prior \u001b[38;5;241m+\u001b[39m log_likelihood\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have a single test sample 'x' and previously calculated 'priors', 'means', and 'stds'\n",
    "\n",
    "# Define the Log Likelihood function first\n",
    "def likelihood(x, mean, std):\n",
    "    # Sum of log-probabilities from Gaussian PDF (Log Likelihood: log P(X=x | C=c))\n",
    "    std_safe = np.where(std == 0, 1e-6, std) \n",
    "    return np.sum(norm.logpdf(x, mean, std_safe))\n",
    "\n",
    "# --- LOG POSTERIOR PROBABILITY CODE (Proportional) ---\n",
    "posteriors = {}\n",
    "for c in classes:\n",
    "    # 1. Log Prior: log P(C=c)\n",
    "    log_prior = np.log(priors[c])\n",
    "\n",
    "    # 2. Log Likelihood: log P(X=x | C=c)\n",
    "    log_likelihood = likelihood(x, means[c], stds[c])\n",
    "\n",
    "    # 3. Log Posterior (Proportional): Sum of Log Prior and Log Likelihood\n",
    "    posteriors[c] = log_prior + log_likelihood\n",
    "# ----------------------------------------------------\n",
    "\n",
    "print(f\"Log Posterior (Proportional) for Class 0: {posteriors[0]:.4f}\")\n",
    "print(f\"Log Posterior (Proportional) for Class 1: {posteriors[1]:.4f}\")\n",
    "\n",
    "# The prediction is the class with the higher value\n",
    "prediction = max(posteriors, key=posteriors.get)\n",
    "print(f\"Prediction: Class {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c22374a9-cf1b-478a-9e2b-50e690df041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(x, mean, std):\n",
    "    \"\"\"Calculates the log-Likelihood for a single sample x.\"\"\"\n",
    "    # Safety: Use a small constant to prevent division by zero for std=0\n",
    "    std_safe = np.where(std == 0, 1e-6, std) \n",
    "    return np.sum(norm.logpdf(x, mean, std_safe))\n",
    "\n",
    "def predict(X):\n",
    "    \"\"\"Predicts the class for an array of samples X.\"\"\"\n",
    "    y_pred = []\n",
    "    # üéØ The variable 'x' is defined here as it iterates through X\n",
    "    for x in X: \n",
    "        posteriors = {}\n",
    "        for c in classes:\n",
    "            # 1. Log Prior\n",
    "            log_prior = np.log(priors[c])\n",
    "            \n",
    "            # 2. Log Likelihood\n",
    "            log_likelihood = likelihood(x, means[c], stds[c])\n",
    "            \n",
    "            # 3. Log Posterior (Proportional)\n",
    "            posteriors[c] = log_prior + log_likelihood\n",
    "        \n",
    "        # Bayesian Decision: Select class with max log-posterior\n",
    "        y_pred.append(max(posteriors, key=posteriors.get))\n",
    "        \n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db4e2834-f6fe-4212-8226-5f50f0c20cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions made successfully.\n"
     ]
    }
   ],
   "source": [
    "# Assuming X_test, y_test are defined from the train_test_split\n",
    "y_pred = predict(X_test)\n",
    "print(\"Predictions made successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cabf4b3-87a0-4e93-9fb0-c89c4727de13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m log_prior \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(priors[c])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 2. Log Likelihood: log P(X=x | C=c)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# This uses the 'likelihood' function defined earlier.\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m likelihood(x, means[c], stds[c])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# --- üéØ THE CALCULATION FOR LOG POSTERIOR (PROPORTIONAL) ---\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Log P(C=c | X=x) ‚àù log P(X=x | C=c) + log P(C=c)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m posteriors[c] \u001b[38;5;241m=\u001b[39m log_prior \u001b[38;5;241m+\u001b[39m log_likelihood\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming 'x' is a single data point from X_test, \n",
    "# and 'c' is the current class (0 or 1) being evaluated.\n",
    "\n",
    "# 1. Log Prior: log P(C=c)\n",
    "log_prior = np.log(priors[c])\n",
    "\n",
    "# 2. Log Likelihood: log P(X=x | C=c)\n",
    "# This uses the 'likelihood' function defined earlier.\n",
    "log_likelihood = likelihood(x, means[c], stds[c])\n",
    "\n",
    "# --- üéØ THE CALCULATION FOR LOG POSTERIOR (PROPORTIONAL) ---\n",
    "# Log P(C=c | X=x) ‚àù log P(X=x | C=c) + log P(C=c)\n",
    "posteriors[c] = log_prior + log_likelihood\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# The result 'posteriors[c]' is the metric used for the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de6e8b-420f-4acf-8338-9e70046299dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "367f4373-7f2c-41b7-8d8d-cfa0e476b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction successful. The error is resolved.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'likelihood', 'priors', 'means', 'stds', and 'classes' are defined\n",
    "\n",
    "def predict(X):\n",
    "    \"\"\"\n",
    "    Predicts the class for an array of samples X.\n",
    "    This function implements the Bayesian Decision Rule.\n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "    # üéØ The variable 'x' is defined here as it iterates through the input array X\n",
    "    for x in X: \n",
    "        posteriors = {}\n",
    "        for c in classes:\n",
    "            # 1. Log Prior\n",
    "            log_prior = np.log(priors[c])\n",
    "            \n",
    "            # 2. Log Likelihood\n",
    "            log_likelihood = likelihood(x, means[c], stds[c])\n",
    "            \n",
    "            # 3. Log Posterior (Proportional)\n",
    "            posteriors[c] = log_prior + log_likelihood\n",
    "        \n",
    "        # Select the class with the maximum log-posterior value\n",
    "        y_pred.append(max(posteriors, key=posteriors.get))\n",
    "        \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Now, call the function using your test data:\n",
    "y_pred = predict(X_test)\n",
    "\n",
    "print(\"Prediction successful. The error is resolved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d11aba-18ad-4193-8b46-ef7d540fcec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
